{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Link Compression\n",
    "\n",
    "This can only be done after the successful elimination of false linkages between contigs\n",
    "\n",
    "Consider the example graph, with contig coverages as follows and\n",
    "```python\n",
    "contig_coverage = {\n",
    "    'c2': 50,\n",
    "    'c1': 150,\n",
    "    'c3': 250,\n",
    "    'c4': 50\n",
    "}\n",
    "```\n",
    "link coverages as below\n",
    "```python\n",
    "link_coverage = {\n",
    "    'c2+c1+': 50,\n",
    "    'c1+c1+': 50,\n",
    "    'c1+c3+': 50,\n",
    "    'c3+c4+': 50,\n",
    "    'c3+c3+': 150,\n",
    "    'c4+c3+': 50\n",
    "}\n",
    "```\n",
    "\n",
    "This is taken from the genome = `c2-c1-c1-c3-c3-c4-c3-c3-c3`\n",
    "\n",
    "The compressed expression is = `c2-c1*x-c3*y-c4-c3*z`\n",
    "In reality derivation of `y` and `z` is nearly impossible, rather an expression generalizing all possible arrangements is possible. For this the coverage information can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contig_4+contig_2+', 'contig_1+contig_4+', 'contig_2+contig_4+', 'contig_4+contig_3-']\n",
      "\n",
      "['contig_3-', 'contig_2+', 'contig_1+', 'contig_4+']\n"
     ]
    }
   ],
   "source": [
    "# all the imports\n",
    "# python imports\n",
    "import copy\n",
    "\n",
    "# initialize with sample data\n",
    "# contig_coverage = {\n",
    "#     'c1': 50,\n",
    "#     'c2': 150,\n",
    "#     'c3': 250,\n",
    "#     'c4': 50,\n",
    "#     'c5': 50\n",
    "# }\n",
    "\n",
    "# link_coverage = {\n",
    "#     'c1+c2+': 50,\n",
    "#     'c2+c2+': 50,\n",
    "#     'c2+c3+': 50,\n",
    "#     'c3+c3+': 50,\n",
    "#     'c3+c2+': 150,\n",
    "#     'c2+c4+': 50,\n",
    "#     'c4+c2+': 50,\n",
    "#     'c2+c5+': 50\n",
    "# }\n",
    "\n",
    "contig_coverage = { 'contig_3-': 1, 'contig_2+': 3, 'contig_1+': 1, 'contig_4+': 10}\n",
    "\n",
    "link_coverage = {'contig_4+contig_2+': 11, 'contig_1+contig_4+': 3, 'contig_2+contig_4+': 49, 'contig_4+contig_3-': 8}\n",
    "\n",
    "\n",
    "\n",
    "read_coverage = 50\n",
    "\n",
    "links = list(link_coverage.keys())\n",
    "contigs = list(contig_coverage.keys())\n",
    "\n",
    "print (links)\n",
    "print ()\n",
    "print (contigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:: graph {'contig_4+': {'contig_2+', 'contig_3-'}, 'contig_2+': {'contig_4+'}, 'contig_1+': {'contig_4+'}, 'contig_3-': set()}\n",
      "INFO:: graph_p {'contig_2+': {'contig_4+'}, 'contig_4+': {'contig_2+', 'contig_1+'}, 'contig_1+': set(), 'contig_3-': {'contig_4+'}}\n",
      "(['contig_3-', 'contig_1+'], [], ['contig_2+', 'contig_4+'])\n",
      "unique cycles [['contig_4+', 'contig_3-'], ['contig_1+', 'contig_4+']]\n",
      "recurrent cycles [['contig_4+', 'contig_2+', 'contig_4+'], ['contig_2+', 'contig_4+', 'contig_2+']]\n",
      "[['contig_4+', 'contig_3-'], ['contig_1+', 'contig_4+']]\n",
      "[['contig_4+', 'contig_2+', 'contig_4+'], ['contig_2+', 'contig_4+', 'contig_2+']]\n"
     ]
    }
   ],
   "source": [
    "class Graph:\n",
    "    \n",
    "    def __init__(self, links, contig_coverage_dict, link_coverage_dict):\n",
    "        self._links = links\n",
    "        self._graph = None\n",
    "        self._graph_p = None\n",
    "        self.contig_coverage_dict = contig_coverage_dict\n",
    "        self.link_coverage_dict = link_coverage_dict\n",
    "\n",
    "    def _name_decomposer(self, link_name):\n",
    "        decomposed = []\n",
    "        temp = \"\"\n",
    "\n",
    "        for c in link_name:\n",
    "            if c == \"+\" or c == \"-\":\n",
    "                contig_name = temp\n",
    "                temp = \"\"\n",
    "                decomposed.extend([contig_name, c])\n",
    "            else: temp += c\n",
    "        return decomposed\n",
    "\n",
    "    def _build_graph(self):\n",
    "        graph = {}\n",
    "        graph_p = {}\n",
    "\n",
    "        for link in self._links:\n",
    "            l_list = self._name_decomposer(link)\n",
    "            l_1 = \"\".join(l_list[0:2])\n",
    "            l_2 = \"\".join(l_list[2:4])\n",
    "\n",
    "            if l_1 not in graph:\n",
    "                graph[l_1] = set()\n",
    "            if l_2 not in graph:\n",
    "                graph[l_2] = set()\n",
    "\n",
    "            if l_2 not in graph_p:\n",
    "                graph_p[l_2] = set()\n",
    "            if l_1 not in graph_p:\n",
    "                graph_p[l_1] = set()\n",
    "\n",
    "            # avoid cycles\n",
    "            if l_1 == l_2: continue\n",
    "\n",
    "            graph[l_1].add(l_2)\n",
    "            graph_p[l_2].add(l_1)\n",
    " \n",
    "        print(\"INFO:: graph\", graph)\n",
    "        print(\"INFO:: graph_p\", graph_p)\n",
    "        \n",
    "        self._graph, self._graph_p = graph, graph_p\n",
    "    \n",
    "    def _get_cycle_dfs(self, start, end):\n",
    "        graph = self._graph\n",
    "        fringe = [(start, [])]\n",
    "        while fringe:\n",
    "            state, path = fringe.pop()\n",
    "            if path and state == end:\n",
    "                yield path\n",
    "                continue\n",
    "            for next_state in graph[state]:\n",
    "                if next_state in path:\n",
    "                    continue\n",
    "                fringe.append((next_state, path+[next_state]))\n",
    "            \n",
    "    # obtain vertices that are worth looking for cycles\n",
    "    def _obtain_critical_vertices(self):\n",
    "        none_set = []\n",
    "        one_set = []\n",
    "        many_set = []\n",
    "        \n",
    "        one_link_set = []\n",
    "        \n",
    "        for key, val in self.contig_coverage_dict.items():\n",
    "            if val == 1:\n",
    "                none_set.append(key)\n",
    "            elif val == 2:\n",
    "                one_set.append(key)\n",
    "            else:\n",
    "                many_set.append(key)\n",
    "                \n",
    "        # TODO do something with such links\n",
    "        \n",
    "        return none_set, one_set, many_set\n",
    "        \n",
    "    def _intersection(self, lst1, lst2): \n",
    "        lst3 = [value for value in lst1 if value in lst2] \n",
    "        return lst3 \n",
    "\n",
    "    def _trace(self):\n",
    "        none_set, one_set, many_set = self._obtain_critical_vertices()\n",
    "        discovered_ones = set()\n",
    "        unique_cycles = []\n",
    "        recurrent_cycles = []\n",
    "        \n",
    "        for vertex in one_set:\n",
    "            cycles = [[vertex] + x for x in self._get_cycle_dfs(vertex, vertex)]\n",
    "            unique_cycles.extend(cycles)\n",
    "            for cycle in cycles:\n",
    "                discovered_ones.update(cycle)\n",
    "            \n",
    "        \n",
    "        for vertex in many_set:\n",
    "            recurrent_cycles.extend([[vertex] + x for x in self._get_cycle_dfs(vertex, vertex)])\n",
    "            \n",
    "        # TODO decide what to do if there are multiplye cycles for unique cycles\n",
    "        \n",
    "        # recurrent cycles must not contain elements from none_set if discovered\n",
    "        temp = recurrent_cycles\n",
    "        recurrent_cycles = []\n",
    "        \n",
    "        while len(temp) > 0:\n",
    "            cycle = temp.pop()\n",
    "            \n",
    "            if len(self._intersection(self._intersection(cycle, none_set), list(discovered_ones))) > 0:\n",
    "                continue\n",
    "            else:\n",
    "                discovered_ones.update(cycle)\n",
    "                recurrent_cycles.append(cycle)\n",
    "            \n",
    "            \n",
    "        \n",
    "        for vertex in none_set:\n",
    "            if not vertex in discovered_ones:\n",
    "                if self._graph_p[vertex]:\n",
    "                    unique_cycles.append([list(self._graph_p[vertex])[0], vertex])\n",
    "                else:\n",
    "                    unique_cycles.append([vertex, list(self._graph[vertex])[0]])\n",
    "\n",
    "        \n",
    "        print(self._obtain_critical_vertices())\n",
    "        \n",
    "        print(\"unique cycles\", unique_cycles)\n",
    "        print(\"recurrent cycles\", recurrent_cycles)\n",
    "        \n",
    "        return unique_cycles, recurrent_cycles\n",
    "        \n",
    "    \n",
    "    def run_resolution(self):\n",
    "        self._build_graph()\n",
    "        \n",
    "#         if self._ensure_euler_path():\n",
    "        return self._trace()\n",
    "#         else:\n",
    "#             raise Exception('Unable to secure an euler path')\n",
    "        \n",
    "        \n",
    "# eg = EulerGraph(['c1+c2+', 'c2+c2+', 'c2+c3+', 'c3+c3+', 'c3+c2+', 'c2+c4+', 'c4+c2+', 'c2+c5+']) \n",
    "# eg = EulerGraph(['c1+c5+', 'c1+c2+', 'c2+c3+', 'c3+c4+', 'c4+c1+', 'c4+c6+',  'c5+c3+',  'c4+c3+', 'c6+c3+']) \n",
    "# eg = Graph(['c1+c5+', 'c1+c2+', 'c2+c3+', 'c3+c4+', 'c4+c3+', 'c4+c6+', 'c4+c1+', 'c6+c3+'],\n",
    "#            {'c1+':2, 'c2+':1,'c6+': 1, 'c3+': 4, 'c4+': 4, 'c5+': 1},\n",
    "#            {}\n",
    "#           ) \n",
    "\n",
    "eg = Graph(link_coverage.keys(),\n",
    "           contig_coverage,\n",
    "           {}\n",
    "          ) \n",
    "\n",
    "trails = eg.run_resolution()\n",
    "\n",
    "for x in trails:\n",
    "    print (x)\n",
    "# euler_trace(graph, graph_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['c1+', 'c2+', 'c3+', 'c4+', 'c1+']]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special comments\n",
    "\n",
    "if a node has no children or parent => coverage must be 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
